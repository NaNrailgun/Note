## 用户服务

### 用户验证

登录之后生成一个随机字符串作为token，将这个用户id，token，失效时间一起存到一张token表里面，然后将token返回给前端。

前端每次请求，都将token放在header里面携带过来，后端先拦截一下，去token表里面查，如果有这个token而且token没过期，那么就放行，否则的话就返回失败信息。

### 用户地址

提供用户对自己地址的管理，增删改查

## 商品服务

商品表：商品id，商品名称，商品介绍，商品分类关联id，缩略图，详细介绍，价格，库存，是否下架（创建者，创建时间，修改者，修改时间）

分类表：分类id，分类等级（一级分类，二级，三级），父分类id，分类名称，排序值（标记删除字段，创建者，创建时间，修改者，修改时间）

先查出固定数量的一级标签，通过这些一级标签查二级标签，通过这些二级标签再去获取三级标签。将三级标签按父标签去分组同一个父标签放进同一个list里面，排序，然后把list放进对应的二级标签对象里面，然后二级标签再按父标签分组也是同一个父标签的放进同一个list里面，排序，然后把list放进相对于的一级标签对象里面，最后把一级标签对象的列表排序之后返回就行了。

首页轮播图表：轮播图id，轮播图url，重定向地址，排序值（删除标识符，创建者，创建时间，修改者，修改时间）

首页配置表：配置项id，商品id，类型（新品？热销？推荐？），排序值（删除标识符，创建者，创建时间，修改者，修改时间）

首页，获取最多数量轮播图，获取三个类型的商品id（写死，可以再搞一个配置表，说要展示什么类型，先查看要展示什么类型，再根据这些类型找商品），根据商品id获取商品信息，返回。

搜索，使用%keyword%，或者分类id（分类id都为3级标签）

分页，需要前端提供想要获取的当前页码，默认的话就是第一页，我们根据我们设定的一页默认的条数去算他前面的数据条数，然后limit（前面的数据条数，条数），然后我们后端除了返回查询的数据还得返回总数据条数和每页默认的数据条数给到前端，前端可以去算说最多请求多少页就停止。

## 订单服务

购物项表：购物项id，用户id，商品id，数量，删除标识。

使用用户id访问购物车，返回未被删除的购物项即可，提供购物车的增删改查。

订单关联的地址表：订单id，收件人姓名（快照），手机（快照），地址（快照）。

订单表：订单id，订单号，用户id，订单总价，订单状态，支付时间，删除标识字段，创建时间。

订单项表：订单项id，订单id，商品id，商品名称（快照），商品图片（快照），商品价格（快照），数量，创建时间。

> 下单流程：
>
> 用户必须先把商品放进购物车才能下单，前端调用下单接口，传入的参数是购物项id和地址id。
>
> 首先对传入的参数进行验证，然后通过购物项id去查出对应的购物项，根据购物项的商品id查出对应的商品信息，根据地址id查出地址。
>
> 然后先去验证一下商品有没有下架和商品的库存够不够，不符合的话直接就返回了。这一步先做检查，减少一些扣库存时候无谓的锁竞争。
>
> 删除购物项，如果发现没得删除，直接返回（在这一步完成幂等）
>
> 计算总价
>
> 生成订单，生成订单号
>
> **调用商品服务**扣库存，这一步使用循环调用扣减，暂时找不出较好的批量扣除库存的方法。
>
> 插入订单
>
> 返回订单号

### 难点：分布式事务的技术选型

然后整个生成订单流程使用分布式事务包裹起来，因为涉及商品服务的扣减库存和订单服务的插入订单，删除购物车。分布式事务框架使用Seata。

对比其他分布式事务解决方案为什么选择Seata？

对比TCC，使用Seata的AT模式，实现简单，对代码侵入性少。

对比用消息队列去实现最终一致性，最终一致性是得自己这边的事务没问题了，提交了，然后发消息调用其他服务，只许成功，不许失败。我们是在订单服务调用商品服务扣减库存，如果扣减成功再生成订单，没法使用最终一致性；如果硬是要使用的话我觉得可以在删除购物车之后，反过来去到商品服务里面，扣库存，然后发消息生成订单，这样来使用最终一致性，但我觉得不太行，这种的话插入订单只许成功不许失败，如果抛异常的话库存没法回滚，用户页面就会一直卡在那里，毕竟后面还要支付，所以我觉得还是有回滚会好一点，所以最后用了Seata。

Seata的话对于普通的读是没获取全局锁的，所以会造成读的隔离是读未提交。在这里的话我是可以接受的，我前面就验证了一下库存够不够，读未提交的隔离级别下如果库存不够那么就说明这个商品是存在竞争的，但可能会有其他事务回滚，所以我干脆返回失败得了，如果还有库存的话，用户再下一次单就行了，影响不大。

亮点：分布式id生成器的实现并使之能被SpringBoot自动装配

springboot自动装配原理

分布式id生成器基于雪花算法实现：

### 雪花算法

![img](项目复盘.assets/1692952e7ee6f2a3)

1) 1位，不用。二进制中最高位为1的都是负数，但是我们生成的id一般都使用整数，所以这个最高位固定是0 

2) 41位，用来记录时间戳（毫秒）。 

3) 41位可以表示2^41−1个数字，如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是：0 至 2^41−1，减1是因为可表示的数值范围是从0开始算的，而不是1。 也就是说41位可以表示2^41−1个毫秒的值，转化成单位年则是(2^41−1)/(1000∗60∗60∗24∗365)=69年 

4) 10位，用来记录工作机器id。 可以部署在2^10=1024个节点，包括5位datacenterId和5位workerId 

5) 5位（bit）可以表示的最大正整数是2^5−1=31，即可以用0、1、2、3、....31这32个数字，来表示不同的datecenterId或workerId

6) 12位，序列号，用来记录同毫秒内产生的不同id。 12位（bit）可以表示的最大正整数是2^12−1=4095，即可以用0、1、2、3、....4094这4095个数字，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号 由于在Java中64bit的整数是long类型，所以在Java中SnowFlake算法生成的id就是long来存储的。



雪花算法线程安全

使用一个内部类封装了序列号和时间，并把这个对象的引用交给Unfase类的原子引用管理。

核心方法：获取下一个id

先获取当前的机器时间，再获取我们封装的对象，会先判断当前时间和这个对象的时间是否相等，如果相等而且这个对象的序列已经超过了最大值就continue继续循环获取当前时间，继续判断；如果没超过那么就新建一个对象，存的是我们当前的时间和序列号+1，然后cas替换对象引用，成功了就直接返回，不成功的话继续循环。如果当前时间已经比对象里存的时间大了，那么就新建一个对象，里面存当前时间，和0序列号，然后cas替换引用，如果更新成功就返回，如果失败就继续循环。

## 支付

支付我没分开来，在订单服务那里。

首先校验一下前端传来的订单id，看看是不是自己的，检查这个订单的状态，如果不是未支付状态的话就直接返回失败。

接下来把我们需要支付订单的订单号给支付宝，让支付宝给我们做幂等。

支付宝回调之后，如果验证成功，那么就把订单的状态改为已支付，同时设置一下支付的时间。



